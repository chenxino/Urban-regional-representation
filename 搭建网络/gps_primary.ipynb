{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gps2xy(lon, lat):\n",
    "    # GPS coordinate: 121.0047308 30.8856365最西 121.9724096 30.8997416最东 121.2702538 30.7056483最南 121.3004672 31.5001065最北\n",
    "    # raster_loc = 1766 685最南 32 742最北 1340 1995最东 1365 192最西\n",
    "    \n",
    "    # calculate coefficient k and b\n",
    "    \"\"\"\n",
    "    gpsX = np.array([[103.9925022, 104.088888], [688, 1729]])\n",
    "    gpsY = np.array([[30.7097699, 30.590786], [856, 2144]])\n",
    "\n",
    "    diffX = gpsX[:, 1] - gpsX[:, 0]\n",
    "    kx = diffX[1] / diffX[0]\n",
    "    bx = gpsX[1, 0] - gpsX[0, 0] * kx\n",
    "\n",
    "    diffY = gpsY[:, 1] - gpsY[:, 0]\n",
    "    ky = diffY[1] / diffY[0]\n",
    "    by = gpsY[1, 0] - gpsY[0, 0] * ky\n",
    "    print(kx, bx) \n",
    "    print(ky, by)\n",
    "    \"\"\"\n",
    "    kx = 1896.250418888416 \n",
    "    bx = -229280.27146698005\n",
    "    ky = -2215.827560963539\n",
    "    by = 69829.24459460145\n",
    " \n",
    " \n",
    "    coordX = np.round(kx * lon + bx).astype(int)\n",
    "    coordY = np.round(ky * lat + by).astype(int)\n",
    "    # print(coordX, coordY)\n",
    "    return (coordX, coordY) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_region_label(lon, lat):\n",
    "    map_table = np.loadtxt('region_labeled.csv')\n",
    "    (coordX, coordY) = gps2xy(lon, lat)\n",
    "    #print(coordX, coordY)\n",
    "    labels = np.zeros(lon.shape[0])\n",
    "    for k in range(len(coordX)):\n",
    "        try:\n",
    "            label = map_table[coordX[k], coordY[k]]\n",
    "            labels[k] = label\n",
    "        except IndexError:\n",
    "            labels[k] = 0\n",
    "    return labels.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_time_by_id(data):\n",
    "    data.sort_values('time', inplace=True) #按时间排序\n",
    "    #print(data.sort_values)\n",
    "    #return data.groupby('id').apply(lambda x: x.sort_values('time'))\n",
    "#     dd = data.groupby('id')\n",
    "#     aa = []\n",
    "#     for key, values in dd:\n",
    "#         values.sort_values('time',inplace=True)\n",
    "#         aa.append(values)\n",
    "#     return aa\n",
    "    return data.groupby('id') #按id分组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hot_point(df, dst):     \n",
    "    # df is a groupby object\n",
    "    line_num = 1\n",
    "\n",
    "    counter = 0\n",
    "    for key, values in df:\n",
    "        rows = values.itertuples()\n",
    "        last_row = next(rows) # last_row是第一行，然后 rows从第二行开始迭代\n",
    "        hot_line = []\n",
    "        for row in rows:\n",
    "            counter += 1\n",
    "            if counter % 500000 == 0:\n",
    "                print(\"processed {},0000 lines\".format(int(counter / 10000)))\n",
    "            if bool(row.empty) ^ bool(last_row.empty):\n",
    "                    # 0 -> 1: leave\n",
    "                    # 1 -> 0: arrive\n",
    "                hot_line.append(row[0])\n",
    "                line_num += 1\n",
    "                last_row = row\n",
    "\n",
    "        values = values.loc[hot_line]\n",
    "\n",
    "        lon_array = values['lng'].as_matrix()\n",
    "        lat_array = values['lat'].as_matrix()\n",
    "        \n",
    "        region_id = get_region_label(lon_array, lat_array)\n",
    "        values['region'] = region_id\n",
    "\n",
    "        mask = (values.region != 0) & (values.region != 1)\n",
    "        values = values[mask]\n",
    "        values.to_csv(dst, index=False, header=False, mode='a+') #mode='a+' 可追加写入\n",
    "        #print(values.head(5))\n",
    "    stat = False\n",
    "    if stat:\n",
    "        print(\"total \" + str(line_num) + \" lines.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(src):\n",
    "    processed_dir = Path(r'../Data/Temp/processed')\n",
    "    filename =  src.name + '.hotpoint'\n",
    "    save_dir = processed_dir / filename\n",
    "    new_file(save_dir)\n",
    "\n",
    "    data = load_gps(src)\n",
    "    print(\"sorting time of {}\".format(src))\n",
    "    data_sorted = sort_time_by_id(data)\n",
    "    print(\"sort complete, hotpoint extracting.\")\n",
    "    extract_hot_point(data_sorted, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'test.csv'\n",
    "data = pd.read_csv(path,sep=',',chunksize = 10000,iterator=True)\n",
    "chunks = []\n",
    "i=0\n",
    "for chunk in data:\n",
    "    chunks.append(chunk)\n",
    "    i+=1\n",
    "\n",
    "df = pd.concat(chunks, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sorted = sort_time_by_id(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "E:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 50,0000 lines\n",
      "processed 100,0000 lines\n",
      "processed 150,0000 lines\n",
      "processed 200,0000 lines\n",
      "processed 250,0000 lines\n",
      "processed 300,0000 lines\n",
      "processed 350,0000 lines\n",
      "processed 400,0000 lines\n",
      "processed 450,0000 lines\n",
      "processed 500,0000 lines\n",
      "processed 550,0000 lines\n",
      "processed 600,0000 lines\n",
      "processed 650,0000 lines\n",
      "processed 700,0000 lines\n",
      "processed 750,0000 lines\n",
      "processed 800,0000 lines\n",
      "processed 850,0000 lines\n",
      "processed 900,0000 lines\n",
      "processed 950,0000 lines\n",
      "processed 1000,0000 lines\n",
      "processed 1050,0000 lines\n",
      "processed 1100,0000 lines\n",
      "processed 1150,0000 lines\n",
      "processed 1200,0000 lines\n",
      "processed 1250,0000 lines\n",
      "processed 1300,0000 lines\n",
      "processed 1350,0000 lines\n",
      "processed 1400,0000 lines\n",
      "processed 1450,0000 lines\n",
      "processed 1500,0000 lines\n",
      "processed 1550,0000 lines\n",
      "processed 1600,0000 lines\n",
      "processed 1650,0000 lines\n",
      "processed 1700,0000 lines\n",
      "processed 1750,0000 lines\n",
      "processed 1800,0000 lines\n",
      "processed 1850,0000 lines\n",
      "processed 1900,0000 lines\n",
      "processed 1950,0000 lines\n",
      "processed 2000,0000 lines\n",
      "processed 2050,0000 lines\n",
      "processed 2100,0000 lines\n",
      "processed 2150,0000 lines\n",
      "processed 2200,0000 lines\n",
      "processed 2250,0000 lines\n",
      "processed 2300,0000 lines\n",
      "processed 2350,0000 lines\n",
      "processed 2400,0000 lines\n",
      "processed 2450,0000 lines\n",
      "processed 2500,0000 lines\n",
      "processed 2550,0000 lines\n",
      "processed 2600,0000 lines\n",
      "processed 2650,0000 lines\n",
      "processed 2700,0000 lines\n",
      "processed 2750,0000 lines\n",
      "processed 2800,0000 lines\n",
      "processed 2850,0000 lines\n",
      "processed 2900,0000 lines\n",
      "processed 2950,0000 lines\n",
      "processed 3000,0000 lines\n",
      "processed 3050,0000 lines\n",
      "processed 3100,0000 lines\n",
      "processed 3150,0000 lines\n",
      "processed 3200,0000 lines\n",
      "processed 3250,0000 lines\n",
      "processed 3300,0000 lines\n",
      "processed 3350,0000 lines\n",
      "processed 3400,0000 lines\n",
      "processed 3450,0000 lines\n",
      "processed 3500,0000 lines\n",
      "processed 3550,0000 lines\n",
      "processed 3600,0000 lines\n",
      "processed 3650,0000 lines\n",
      "processed 3700,0000 lines\n",
      "processed 3750,0000 lines\n",
      "processed 3800,0000 lines\n",
      "processed 3850,0000 lines\n",
      "processed 3900,0000 lines\n",
      "processed 3950,0000 lines\n",
      "processed 4000,0000 lines\n",
      "processed 4050,0000 lines\n",
      "processed 4100,0000 lines\n",
      "processed 4150,0000 lines\n",
      "processed 4200,0000 lines\n",
      "processed 4250,0000 lines\n",
      "processed 4300,0000 lines\n",
      "processed 4350,0000 lines\n",
      "processed 4400,0000 lines\n",
      "processed 4450,0000 lines\n",
      "processed 4500,0000 lines\n",
      "processed 4550,0000 lines\n",
      "processed 4600,0000 lines\n",
      "processed 4650,0000 lines\n",
      "processed 4700,0000 lines\n",
      "processed 4750,0000 lines\n",
      "processed 4800,0000 lines\n",
      "processed 4850,0000 lines\n",
      "processed 4900,0000 lines\n",
      "processed 4950,0000 lines\n",
      "processed 5000,0000 lines\n",
      "processed 5050,0000 lines\n",
      "processed 5100,0000 lines\n",
      "processed 5150,0000 lines\n",
      "processed 5200,0000 lines\n",
      "processed 5250,0000 lines\n",
      "processed 5300,0000 lines\n",
      "processed 5350,0000 lines\n",
      "processed 5400,0000 lines\n",
      "processed 5450,0000 lines\n",
      "processed 5500,0000 lines\n",
      "processed 5550,0000 lines\n",
      "processed 5600,0000 lines\n",
      "processed 5650,0000 lines\n",
      "processed 5700,0000 lines\n",
      "processed 5750,0000 lines\n",
      "processed 5800,0000 lines\n",
      "processed 5850,0000 lines\n",
      "processed 5900,0000 lines\n",
      "processed 5950,0000 lines\n",
      "processed 6000,0000 lines\n",
      "processed 6050,0000 lines\n",
      "processed 6100,0000 lines\n",
      "processed 6150,0000 lines\n",
      "processed 6200,0000 lines\n",
      "processed 6250,0000 lines\n",
      "processed 6300,0000 lines\n",
      "processed 6350,0000 lines\n",
      "processed 6400,0000 lines\n",
      "processed 6450,0000 lines\n",
      "processed 6500,0000 lines\n",
      "processed 6550,0000 lines\n",
      "processed 6600,0000 lines\n",
      "processed 6650,0000 lines\n",
      "processed 6700,0000 lines\n",
      "processed 6750,0000 lines\n",
      "processed 6800,0000 lines\n",
      "processed 6850,0000 lines\n",
      "processed 6900,0000 lines\n",
      "processed 6950,0000 lines\n",
      "processed 7000,0000 lines\n",
      "processed 7050,0000 lines\n",
      "processed 7100,0000 lines\n",
      "processed 7150,0000 lines\n",
      "processed 7200,0000 lines\n",
      "processed 7250,0000 lines\n",
      "processed 7300,0000 lines\n",
      "processed 7350,0000 lines\n",
      "processed 7400,0000 lines\n",
      "processed 7450,0000 lines\n",
      "processed 7500,0000 lines\n",
      "processed 7550,0000 lines\n",
      "processed 7600,0000 lines\n",
      "processed 7650,0000 lines\n",
      "processed 7700,0000 lines\n",
      "processed 7750,0000 lines\n",
      "processed 7800,0000 lines\n",
      "processed 7850,0000 lines\n",
      "processed 7900,0000 lines\n",
      "processed 7950,0000 lines\n",
      "processed 8000,0000 lines\n",
      "processed 8050,0000 lines\n",
      "processed 8100,0000 lines\n",
      "processed 8150,0000 lines\n",
      "processed 8200,0000 lines\n",
      "processed 8250,0000 lines\n",
      "processed 8300,0000 lines\n",
      "processed 8350,0000 lines\n",
      "processed 8400,0000 lines\n",
      "processed 8450,0000 lines\n",
      "processed 8500,0000 lines\n",
      "processed 8550,0000 lines\n",
      "processed 8600,0000 lines\n",
      "processed 8650,0000 lines\n",
      "processed 8700,0000 lines\n",
      "processed 8750,0000 lines\n",
      "processed 8800,0000 lines\n",
      "processed 8850,0000 lines\n",
      "processed 8900,0000 lines\n",
      "processed 8950,0000 lines\n",
      "processed 9000,0000 lines\n",
      "processed 9050,0000 lines\n",
      "processed 9100,0000 lines\n",
      "processed 9150,0000 lines\n",
      "processed 9200,0000 lines\n",
      "processed 9250,0000 lines\n",
      "processed 9300,0000 lines\n",
      "processed 9350,0000 lines\n",
      "processed 9400,0000 lines\n",
      "processed 9450,0000 lines\n"
     ]
    }
   ],
   "source": [
    "extract_hot_point(data_sorted, Path(r'E:\\Program Files\\jupyter_code\\code\\data\\total.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hp(src):\n",
    "    src = str(src)\n",
    "    try:\n",
    "        print(\"reading from \" + src)\n",
    "        data = pd.read_table(src, names=['id', 'status', 'time', 'latitude', 'longitude', 'region'], \n",
    "        sep=',', engine='c', float_precision='high')\n",
    "        print(src + \" is sucessfully loaded!\")\n",
    "        return data\n",
    "    except:\n",
    "        print(src + \" is not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hours(arr):\n",
    "    #@param arr: '2015-04-01 14:14:53'\n",
    "    #print(arr.head(10))\n",
    "    #print(arr)\n",
    "    partitioned = arr.time.split(' ')\n",
    "    if len(partitioned)<2:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading from data/total.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: read_table is deprecated, use read_csv instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/total.txt is sucessfully loaded!\n",
      "[883, 4225, 4226, 5006, 6963, 8106, 13400, 31146, 32178, 32179, 32180, 32181, 32182, 32183, 32184, 32185, 32186, 32187, 34373, 34374, 34375, 34537, 51498, 52317, 52318, 61826, 70801, 70802, 70803, 70804, 70805, 75019, 82505, 83195, 93445, 98111, 98112, 98659, 98660, 112300, 112301, 114479, 125027, 125808, 126027, 134960, 134961, 138278, 145281, 146914, 147163, 148673, 149956, 149957, 150695, 158462, 164617, 167286, 167287, 171588, 171589, 171590, 171856, 173339, 174149, 174865, 175402, 181584, 182023, 183027, 188715, 188827, 196654, 196655, 196656, 196657, 208592, 211924, 214184, 223437, 223733, 227523, 229000, 229236, 232647, 235552, 235651, 238259, 242243, 253142, 254847, 255061, 260845, 261026, 261375, 262307, 262308, 262309, 262310, 262311, 262312, 262313, 262314, 262315, 262316, 262317, 262318, 262319, 262320, 262321, 262322, 262323, 262324, 262325, 262326, 262327, 262328, 262329, 262330, 262331, 262332, 262333, 262334, 262335, 262336, 262695, 262696, 262697, 262698, 262699, 262700, 262701, 262702, 269580, 269581, 269582, 272827, 272828, 274370, 288489, 297576, 299638, 300267, 303017, 303018, 305183, 305184, 305185, 305186, 305187, 305188, 305595, 310649, 311007, 315094, 315095, 316676, 316677, 316678, 316679, 316680, 316681, 316682, 316683, 316684, 318322, 318323, 321526, 322683, 323719, 323831, 329652, 329886, 329887, 331880, 345974, 347290, 347291, 347292, 347293, 347294, 347295, 347296, 347297, 347298, 347299, 347300, 347301, 347302, 347303, 347304, 347305, 347306, 347307, 347308, 347309, 347310, 347311, 347312, 347313, 347314, 347315, 347316, 347317, 347318, 347319, 347320, 347321, 347322, 347323, 347324, 347325, 347326, 358184, 358185, 358186, 358187, 358188, 358189, 358190, 358191, 358192, 358193, 358194, 358195, 360734, 363552, 402202, 409613, 409989, 421546, 429102, 429622, 431656, 437008, 438882, 438883, 438921, 441232, 441233, 441234, 441346, 442957, 450581, 450582, 450583, 450584, 450585, 450586, 450587, 467393, 469344, 470511, 470512, 470513, 470514, 470515, 470516, 470517, 470518, 472391, 472392, 491112, 493221, 497370, 502596, 502597, 503424, 504626, 504803, 511090, 511091, 515800, 518986, 519125, 528064, 528065, 529821, 529822, 529823, 529824, 529825, 529826, 529827, 529828, 529829, 529830, 529831, 532895, 537858, 545536, 549266, 549267, 549268, 549269, 550382, 550383, 550384, 550385, 550386, 550387, 550388, 550389, 550390, 550412, 550606, 550607, 550608, 550609, 550610, 550611, 550612, 550613, 550614, 550615, 550616, 550617, 550618, 550619, 550620, 550621, 550622, 550623, 550624, 550625, 550626, 550627, 550628, 550629, 550630, 550631, 550632, 550633, 550634, 550635, 558432, 558433, 561583, 563856, 563857, 563858, 563859, 563860, 563861, 563862, 563863, 563864, 565561, 565930, 565931, 576951, 586043, 587513, 587514, 587515, 587516, 587517, 587518, 587519, 587520, 587521, 587522, 587523, 587524, 594404, 594405, 594406, 596414, 599448, 602103, 602104, 602105, 602106, 602107, 602108, 602109, 602110, 602111, 602112, 602113, 602114, 602115, 602116, 602117, 602118, 602119, 602120, 602121, 602122, 602123, 602124, 602125, 608573, 619694, 626945, 626946, 626947, 626948, 626949, 626950, 626951, 626952, 628880, 629428, 629429, 629430, 639148, 642300, 644130, 644131, 644132, 644133, 644134, 644135, 644136, 644137, 644138, 644139, 644140, 644141, 644142, 644143, 644144, 644145, 644146, 644147, 644148, 644149, 644150, 644151, 644152, 644153, 644154, 644155, 644156, 644157, 644158, 644159, 644160, 644161, 644162, 644163, 644164, 644165, 644166, 644167, 644168, 644169, 644170, 644171, 644172, 644173, 644174, 644175, 644176, 644177, 644178, 644179, 644180, 644181, 644182, 644183, 644184, 645330, 656774, 658739, 658795, 673491, 673492, 673493, 673494, 673495, 673496, 673497, 674696, 675065, 687413, 687414, 687415, 687416, 687417, 687418, 687419]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "data = load_hp('data/total.txt')\n",
    "it = data.itertuples()\n",
    "a = []\n",
    "for row in it:\n",
    "    #print(row[0])\n",
    "    if extract_hours(row):\n",
    "        a.append(row[0])\n",
    "print(a)\n",
    "aa = data.drop(index=a)\n",
    "print('1')\n",
    "aa.to_csv('data/total2.txt', index=False, header=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def main():\n",
    "    # flag: True for preprocess the raw data, sort by time and drop duplicate GPS coordinates\n",
    "    doPreprocess = True\n",
    "    #flag: True for build mobility pattern, extract \n",
    "\n",
    "    MAX_CORE = cpu_count() - 1\n",
    "    \n",
    "    start_time = time.time()\n",
    "    if doPreprocess:\n",
    "        source_dir = Path(r'E:\\Program Files\\jupyter_code\\出租车\\data')\n",
    "        #source_dir = Path(r'/home/dlbox/Documents/func_region/Data/Temp/gcj09')\n",
    "\n",
    "        # data_range = range(24, 30+1)\n",
    "        # days: 24-30\n",
    "        \n",
    "        source_dirs = [x for x in source_dir.glob('*.txt')]\n",
    "        ## process the raw data, read, sort, and drop duplicates\n",
    "        ##sort data by time groupby car ID\n",
    "        p = Pool(processes=7)\n",
    "        p.map(process_data, source_dirs)\n",
    "        p.close()\n",
    "        p.join()\n",
    "    finish_time = time.time()\n",
    "    print(\"used {}s\".format(finish_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
