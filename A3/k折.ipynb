{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87, 16)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('feature_pre.csv')\n",
    "feature = train.iloc[:,:-1]\n",
    "feature.head()\n",
    "feature.shape\n",
    "# test = pd.read_csv('./all/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = pd.read_csv('feature3_pre.csv')\n",
    "feature2 = train.iloc[:,:-1]\n",
    "feature2.head()\n",
    "feature2.shape\n",
    "# test = pd.read_csv('./all/test.csv')\n",
    "train_features2 = feature2.values.astype(np.float32)\n",
    "train_features2 = torch.from_numpy(train_features2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对预测的价格取 log\n",
    "train['price'] = np.log(train['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取训练集和验证集的特征\n",
    "train_features = feature.values.astype(np.float32)\n",
    "train_features = torch.from_numpy(train_features)\n",
    "\n",
    "# 提取训练集和验证集的label\n",
    "train_labels = train['price'].values.astype(np.float32)\n",
    "train_labels = torch.from_numpy(train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def get_model(feat_dim):\n",
    "    net = nn.Sequential(\n",
    "        nn.Linear(feat_dim, 1)\n",
    "    )\n",
    "    return net\n",
    "\n",
    "net = get_model(4)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(x, y, batch_size, shuffle):\n",
    "    dataset = TensorDataset(x, y)\n",
    "    return DataLoader(dataset, batch_size, shuffle=shuffle, num_workers=4)\n",
    "\n",
    "def get_rmse(model, feature, label, use_gpu):\n",
    "    if use_gpu:\n",
    "        feature = feature.cuda()\n",
    "        label = label.cuda()\n",
    "    model.eval()\n",
    "    mse_loss = nn.MSELoss()\n",
    "    with torch.no_grad():\n",
    "        pred = model(feature)\n",
    "    # clipped_pred = pred.clamp(1, float('inf'))\n",
    "    rmse = (mse_loss(pred, label)).sqrt()\n",
    "\n",
    "    return rmse.item()\n",
    "\n",
    "def pred(net, test_labels, test_features):\n",
    "    net = net.eval()\n",
    "    net = net.cpu()\n",
    "    with torch.no_grad():\n",
    "        preds = net(test_features)\n",
    "    preds = np.exp(preds.numpy())\n",
    "    test_labels = np.exp(test_labels.numpy())\n",
    "\n",
    "    print(preds,test_labels)\n",
    "    MAE = (np.abs(preds - test_labels)).sum(axis=0)/test_features.shape[0]\n",
    "    MRE = MAE/(test_labels.sum(axis=0))\n",
    "    return MRE[0], MAE[0]\n",
    "\n",
    "def train_model(model, x_train, y_train, x_valid, y_valid, epochs, lr, weight_decay, batch_size, use_gpu = 0):\n",
    "    if use_gpu:\n",
    "        model = model.cuda()\n",
    "    metric_log = defaultdict(list)\n",
    "\n",
    "    train_data = get_data(x_train, y_train, batch_size, True)\n",
    "    if x_valid is not None:\n",
    "        valid_data = get_data(x_valid, y_valid, batch_size, False)\n",
    "    else:\n",
    "        valid_data = None\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for e in range(epochs):\n",
    "        # 训练模型\n",
    "        model.train()\n",
    "        for data in train_data:\n",
    "            x, y = data\n",
    "            if use_gpu:\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "            # forward\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        metric_log['train_rmse'].append(get_rmse(model, x_train, y_train, use_gpu))\n",
    "        metric_log['valid_rmse'] = []\n",
    "        # 测试模型\n",
    "        metric_log['valid_MAE']\n",
    "\n",
    "        if x_valid is not None:\n",
    "            metric_log['valid_rmse'].append(get_rmse(model, x_valid, y_valid, use_gpu))\n",
    "        \n",
    "            print_str = 'epoch: {}, train rmse: {:.3f}, valid rmse: {:.3f}' \\\n",
    "                .format(e + 1, metric_log['train_rmse'][-1], metric_log['valid_rmse'][-1])\n",
    "        else:\n",
    "            print_str = 'epoch: {}, train rmse: {:.3f}'.format(e + 1, metric_log['train_rmse'][-1])\n",
    "    if (e + 1) % 10 == 0:\n",
    "        print(print_str)\n",
    "        print()\n",
    "    print(metric_log['valid_rmse'])\n",
    "\n",
    "\n",
    "    return metric_log['train_rmse'], metric_log['valid_rmse']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program Files\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:431: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "E:\\Program Files\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:431: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([4, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "E:\\Program Files\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:431: UserWarning: Using a target size (torch.Size([68])) that is different to the input size (torch.Size([68, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "E:\\Program Files\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:431: UserWarning: Using a target size (torch.Size([17])) that is different to the input size (torch.Size([17, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 300, train rmse: 0.606, valid rmse: 0.448\n",
      "\n",
      "[0.4479233920574188]\n",
      "[[3835.4673]\n",
      " [4415.3496]\n",
      " [3891.441 ]\n",
      " [3915.3174]\n",
      " [4328.3057]\n",
      " [5621.1025]\n",
      " [4648.1445]\n",
      " [3817.262 ]\n",
      " [4928.653 ]\n",
      " [3860.5684]\n",
      " [3879.1467]\n",
      " [3858.496 ]\n",
      " [3953.0051]\n",
      " [3857.2048]\n",
      " [3890.235 ]\n",
      " [3793.3867]\n",
      " [3898.127 ]] [3369.2617 4689.294  2209.4387 2796.036  8908.591  8684.764  4761.382\n",
      " 2894.231  4562.3296 4612.7817 2745.2014 5317.6353 6840.2446 3758.952\n",
      " 3306.8052 1913.8713 2738.2239]\n",
      "5-fold validation: avg train rmse 0.121278, avg valid rmse 0.089585, avg valid MRE 0.002082, avg valid MAE 154.279578\n"
     ]
    }
   ],
   "source": [
    "# K折交叉验证\n",
    "def get_k_fold_data(k, i, X, y):\n",
    "    # 返回第i折交叉验证时所需要的训练和验证数据\n",
    "    assert k > 1\n",
    "    fold_size = X.shape[0] // k\n",
    "    X_train, y_train = None, None\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size)\n",
    "        X_part, y_part = X[idx, :], y[idx]\n",
    "        if j == i:\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None:\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else:\n",
    "            X_train = torch.cat((X_train, X_part), dim=0)\n",
    "            y_train = torch.cat((y_train, y_part), dim=0)\n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "def k_fold(k, X_train, y_train, num_epochs,\n",
    "           learning_rate, weight_decay, batch_size):\n",
    "    train_l_sum, valid_l_sum = 0, 0\n",
    "    MRE, MAE = 0, 0\n",
    "    \n",
    "    for i in range(k):\n",
    "        a, b, c, d = get_k_fold_data(k, i, X_train, y_train)\n",
    "        if i==4:\n",
    "            net = get_model(X_train.shape[1])\n",
    "            train_ls, valid_ls = train_model(net, a, b, c, d, num_epochs, learning_rate, weight_decay, batch_size)\n",
    "            train_l_sum += train_ls[-1]\n",
    "            valid_l_sum += valid_ls[-1]\n",
    "\n",
    "            a,b = pred(net, d, c)\n",
    "\n",
    "            MRE += a\n",
    "            MAE += b\n",
    "#         if i==0:\n",
    "#             figsize = (10, 5)\n",
    "#             fig = plt.figure(figsize=figsize)\n",
    "#             #print(train_ls)\n",
    "#             plt.plot(train_ls, color='red', label='train')\n",
    "#             plt.plot(valid_ls, color='green', label='vaild')\n",
    "#             plt.legend(loc='best')\n",
    "#             plt.xlabel('epochs')\n",
    "#             plt.ylabel('loss')\n",
    "#             plt.show()\n",
    "\n",
    "#         if i == 0:\n",
    "#             d2l.semilogy(range(1, num_epochs + 1), train_ls, 'epochs', 'rmse',\n",
    "#                          range(1, num_epochs + 1), valid_ls,\n",
    "#                          ['train', 'valid'])\n",
    "       # print('fold %d, train rmse %f, valid rmse %f' % (i, train_ls[-1], valid_ls[-1]))\n",
    "    return train_l_sum / k, valid_l_sum / k, MRE/k, MAE/k\n",
    "\n",
    "# 模型选择\n",
    "k, num_epochs, lr, weight_decay, batch_size = 5, 300, 0.05, 0, 64\n",
    "train_l, valid_l, m1, m2 = k_fold(k, train_features, train_labels, num_epochs, lr, weight_decay, batch_size)\n",
    "\n",
    "print('%d-fold validation: avg train rmse %f, avg valid rmse %f, avg valid MRE %f, avg valid MAE %f' % (k, train_l, valid_l, m1, m2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 300, train rmse: 0.598, valid rmse: 0.444\n",
      "\n",
      "[0.443930059671402]\n",
      "[[3833.0503]\n",
      " [4316.15  ]\n",
      " [3876.1477]\n",
      " [3898.3945]\n",
      " [4269.044 ]\n",
      " [5349.849 ]\n",
      " [4510.4927]\n",
      " [3811.7363]\n",
      " [4760.633 ]\n",
      " [3850.2366]\n",
      " [3863.069 ]\n",
      " [3849.451 ]\n",
      " [3932.5425]\n",
      " [3847.2637]\n",
      " [3871.3157]\n",
      " [3791.788 ]\n",
      " [3884.952 ]] [3369.2617 4689.294  2209.4387 2796.036  8908.591  8684.764  4761.382\n",
      " 2894.231  4562.3296 4612.7817 2745.2014 5317.6353 6840.2446 3758.952\n",
      " 3306.8052 1913.8713 2738.2239]\n",
      "5-fold validation: avg train rmse 0.119668, avg valid rmse 0.088786, avg valid MRE 0.001943, avg valid MAE 143.984314\n"
     ]
    }
   ],
   "source": [
    "k, num_epochs, lr, weight_decay, batch_size = 5, 300, 0.05, 0, 64\n",
    "train_l, valid_l, m1, m2 = k_fold(k, train_features2, train_labels, num_epochs, lr, weight_decay, batch_size)\n",
    "\n",
    "print('%d-fold validation: avg train rmse %f, avg valid rmse %f, avg valid MRE %f, avg valid MAE %f' % (k, train_l, valid_l, m1, m2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K折交叉验证\n",
    "def get_k_fold_data(k, i, X, y):\n",
    "    # 返回第i折交叉验证时所需要的训练和验证数据\n",
    "    assert k > 1\n",
    "    fold_size = X.shape[0] // k\n",
    "    X_train, y_train = None, None\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size)\n",
    "        X_part, y_part = X[idx, :], y[idx]\n",
    "        if j == i:\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None:\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else:\n",
    "            X_train = torch.cat((X_train, X_part), dim=0)\n",
    "            y_train = torch.cat((y_train, y_part), dim=0)\n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "def k_fold(k, X_train, y_train, num_epochs,\n",
    "           learning_rate, weight_decay, batch_size):\n",
    "    train_l_sum, valid_l_sum = 0, 0\n",
    "    MRE, MAE = 0, 0\n",
    "    for i in range(k):\n",
    "        a, b, c, d = get_k_fold_data(k, i, X_train, y_train)\n",
    "        \n",
    "        net = get_model(X_train.shape[1])\n",
    "        train_ls, valid_ls = train_model(net, a, b, c, d, num_epochs, learning_rate, weight_decay, batch_size)\n",
    "        train_l_sum += train_ls[-1]\n",
    "        valid_l_sum += valid_ls[-1]\n",
    "        \n",
    "        a,b = pred(net, d, c)\n",
    "\n",
    "        MRE += a\n",
    "        MAE += b\n",
    "        if i==0:\n",
    "            figsize = (10, 5)\n",
    "            fig = plt.figure(figsize=figsize)\n",
    "            print(train_ls)\n",
    "            print(valid_ls)\n",
    "            plt.plot(train_ls, color='red', label='train')\n",
    "            plt.plot(valid_ls, color='green', label='vaild')\n",
    "            plt.legend(loc='best')\n",
    "            plt.xlabel('epochs')\n",
    "            plt.ylabel('loss')\n",
    "            plt.show()\n",
    "\n",
    "#         if i == 0:\n",
    "#             d2l.semilogy(range(1, num_epochs + 1), train_ls, 'epochs', 'rmse',\n",
    "#                          range(1, num_epochs + 1), valid_ls,\n",
    "#                          ['train', 'valid'])\n",
    "        print('fold %d, train rmse %f, valid rmse %f' % (i, train_ls[-1], valid_ls[-1]))\n",
    "    return train_l_sum / k, valid_l_sum / k, MRE/k, MAE/k\n",
    "\n",
    "# 模型选择\n",
    "k, num_epochs, lr, weight_decay, batch_size = 5, 300, 0.05, 0, 64\n",
    "train_l, valid_l, m1, m2 = k_fold(k, train_features, train_labels, num_epochs, lr, weight_decay, batch_size)\n",
    "\n",
    "print('%d-fold validation: avg train rmse %f, avg valid rmse %f, avg valid MRE %f, avg valid MAE %f' % (k, train_l, valid_l, m1, m2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"/home/kesci/input\")\n",
    "import d2lzh1981 as d2l\n",
    "print(torch.__version__)\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "\n",
    "test_data = pd.read_csv(\"/home/kesci/input/houseprices2807/house-prices-advanced-regression-techniques/test.csv\")\n",
    "train_data = pd.read_csv(\"/home/kesci/input/houseprices2807/house-prices-advanced-regression-techniques/train.csv\")\n",
    "\n",
    "all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:]))\n",
    "\n",
    "# 数据预处理\n",
    "numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\n",
    "all_features[numeric_features] = all_features[numeric_features].apply(\n",
    "    lambda x: (x - x.mean()) / (x.std()))\n",
    "# 标准化后，每个数值特征的均值变为0，所以可以直接用0来替换缺失值\n",
    "all_features[numeric_features] = all_features[numeric_features].fillna(0)\n",
    "\n",
    "\n",
    "# dummy_na=True将缺失值也当作合法的特征值并为其创建指示特征\n",
    "all_features = pd.get_dummies(all_features, dummy_na=True)\n",
    "all_features.shape\n",
    "\n",
    "n_train = train_data.shape[0]\n",
    "train_features = torch.tensor(all_features[:n_train].values, dtype=torch.float)\n",
    "test_features = torch.tensor(all_features[n_train:].values, dtype=torch.float)\n",
    "train_labels = torch.tensor(train_data.SalePrice.values, dtype=torch.float).view(-1, 1)\n",
    "\n",
    "# 训练模型\n",
    "loss = torch.nn.MSELoss()\n",
    "\n",
    "def get_net(feature_num):\n",
    "    net = nn.Linear(feature_num, 1)\n",
    "    for param in net.parameters():\n",
    "        nn.init.normal_(param, mean=0, std=0.01)\n",
    "    return net\n",
    "\n",
    "\n",
    "def log_rmse(net, features, labels):\n",
    "    with torch.no_grad():\n",
    "        # 将小于1的值设成1，使得取对数时数值更稳定\n",
    "        clipped_preds = torch.max(net(features), torch.tensor(1.0))\n",
    "        rmse = torch.sqrt(2 * loss(clipped_preds.log(), labels.log()).mean())\n",
    "    return rmse.item()\n",
    "\n",
    "\n",
    "def train(net, train_features, train_labels, test_features, test_labels,\n",
    "          num_epochs, learning_rate, weight_decay, batch_size):\n",
    "    train_ls, test_ls = [], []\n",
    "    dataset = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "    train_iter = torch.utils.data.DataLoader(dataset, batch_size, shuffle=True)\n",
    "    # 这里使用了Adam优化算法\n",
    "    optimizer = torch.optim.Adam(params=net.parameters(), lr=learning_rate, weight_decay=weight_decay) \n",
    "    net = net.float()\n",
    "    for epoch in range(num_epochs):\n",
    "        for X, y in train_iter:\n",
    "            l = loss(net(X.float()), y.float())\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "        train_ls.append(log_rmse(net, train_features, train_labels))\n",
    "        if test_labels is not None:\n",
    "            test_ls.append(log_rmse(net, test_features, test_labels))\n",
    "    return train_ls, test_ls\n",
    "\n",
    "\n",
    "# K折交叉验证\n",
    "def get_k_fold_data(k, i, X, y):\n",
    "    # 返回第i折交叉验证时所需要的训练和验证数据\n",
    "    assert k > 1\n",
    "    fold_size = X.shape[0] // k\n",
    "    X_train, y_train = None, None\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size)\n",
    "        X_part, y_part = X[idx, :], y[idx]\n",
    "        if j == i:\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None:\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else:\n",
    "            X_train = torch.cat((X_train, X_part), dim=0)\n",
    "            y_train = torch.cat((y_train, y_part), dim=0)\n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "def k_fold(k, X_train, y_train, num_epochs,\n",
    "           learning_rate, weight_decay, batch_size):\n",
    "    train_l_sum, valid_l_sum = 0, 0\n",
    "    for i in range(k):\n",
    "        data = get_k_fold_data(k, i, X_train, y_train)\n",
    "        net = get_net(X_train.shape[1])\n",
    "        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate,\n",
    "                                   weight_decay, batch_size)\n",
    "        train_l_sum += train_ls[-1]\n",
    "        valid_l_sum += valid_ls[-1]\n",
    "        if i == 0:\n",
    "            d2l.semilogy(range(1, num_epochs + 1), train_ls, 'epochs', 'rmse',\n",
    "                         range(1, num_epochs + 1), valid_ls,\n",
    "                         ['train', 'valid'])\n",
    "        print('fold %d, train rmse %f, valid rmse %f' % (i, train_ls[-1], valid_ls[-1]))\n",
    "    return train_l_sum / k, valid_l_sum / k\n",
    "\n",
    "# 模型选择\n",
    "k, num_epochs, lr, weight_decay, batch_size = 5, 100, 5, 0, 64\n",
    "train_l, valid_l = k_fold(k, train_features, train_labels, num_epochs, lr, weight_decay, batch_size)\n",
    "print('%d-fold validation: avg train rmse %f, avg valid rmse %f' % (k, train_l, valid_l))\n",
    "\n",
    "\n",
    "# 预测\n",
    "def train_and_pred(train_features, test_features, train_labels, test_data,\n",
    "                   num_epochs, lr, weight_decay, batch_size):\n",
    "    net = get_net(train_features.shape[1])\n",
    "    train_ls, _ = train(net, train_features, train_labels, None, None,\n",
    "                        num_epochs, lr, weight_decay, batch_size)\n",
    "    d2l.semilogy(range(1, num_epochs + 1), train_ls, 'epochs', 'rmse')\n",
    "    print('train rmse %f' % train_ls[-1])\n",
    "    preds = net(test_features).detach().numpy()\n",
    "    test_data['SalePrice'] = pd.Series(preds.reshape(1, -1)[0])\n",
    "    submission = pd.concat([test_data['Id'], test_data['SalePrice']], axis=1)\n",
    "    submission.to_csv('./submission.csv', index=False)\n",
    "    # sample_submission_data = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/sample_submission.csv\")\n",
    "\n",
    "train_and_pred(train_features, test_features, train_labels, test_data, num_epochs, lr, weight_decay, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
